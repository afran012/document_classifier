{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del Modelo de Clasificación de Páginas de PDF\n",
    "\n",
    "Este notebook entrena un modelo de CNN para identificar las primeras páginas en documentos PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "\n",
    "# Configurar rutas\n",
    "PROCESSED_DIR = '../data/processed'\n",
    "LABELS_FILE = '../data/labels.json'\n",
    "MODEL_DIR = '../data/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar existencia de archivos y directorios necesarios\n",
    "print(\"Verificando archivos y directorios...\")\n",
    "if not os.path.exists(LABELS_FILE):\n",
    "    raise FileNotFoundError(f\"No se encontró el archivo de etiquetas: {LABELS_FILE}\")\n",
    "if not os.path.exists(PROCESSED_DIR):\n",
    "    raise FileNotFoundError(f\"No se encontró el directorio de imágenes procesadas: {PROCESSED_DIR}\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "print(\"✓ Verificación completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['# Entrenamiento del Modelo de Clasificación de Páginas de PDF\\n',\n",
       "    '\\n',\n",
       "    'Este notebook entrena un modelo de CNN para identificar las primeras páginas en documentos PDF.']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['# Importar librerías necesarias\\n',\n",
       "    'import sys\\n',\n",
       "    'import os\\n',\n",
       "    'import json\\n',\n",
       "    'import numpy as np\\n',\n",
       "    'import cv2\\n',\n",
       "    'import matplotlib.pyplot as plt\\n',\n",
       "    'from sklearn.model_selection import train_test_split\\n',\n",
       "    'import tensorflow as tf\\n',\n",
       "    'from tensorflow.keras.models import Sequential\\n',\n",
       "    'from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\\n',\n",
       "    '\\n',\n",
       "    '# Configurar rutas\\n',\n",
       "    \"PROCESSED_DIR = '../data/processed/2-TITULOS-15-DE-NOVIEMBRE-2024-1-30'\\n\",\n",
       "    \"LABELS_FILE = '../data/labels.json'\\n\",\n",
       "    \"MODEL_DIR = '../data/models'\"]},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['# Verificar existencia de archivos y directorios necesarios\\n',\n",
       "    'print(\"Verificando archivos y directorios...\")\\n',\n",
       "    'if not os.path.exists(LABELS_FILE):\\n',\n",
       "    '    raise FileNotFoundError(f\"No se encontró el archivo de etiquetas: {LABELS_FILE}\")\\n',\n",
       "    'if not os.path.exists(PROCESSED_DIR):\\n',\n",
       "    '    raise FileNotFoundError(f\"No se encontró el directorio de imágenes procesadas: {PROCESSED_DIR}\")\\n',\n",
       "    'os.makedirs(MODEL_DIR, exist_ok=True)\\n',\n",
       "    'print(\"✓ Verificación completada\")']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['# Cargar etiquetas\\n',\n",
       "    'print(\"Cargando etiquetas...\")\\n',\n",
       "    \"with open(LABELS_FILE, 'r') as f:\\n\",\n",
       "    '    labels = json.load(f)\\n',\n",
       "    'print(f\"✓ Se cargaron etiquetas para {len(labels)} PDFs\")']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['# Preparar datos para entrenamiento\\n',\n",
       "    'print(\"Preparando datos para entrenamiento...\")\\n',\n",
       "    'X = []\\n',\n",
       "    'y = []\\n',\n",
       "    '\\n',\n",
       "    'for pdf_name, info in labels.items():\\n',\n",
       "    '    pdf_dir = os.path.join(PROCESSED_DIR, pdf_name)\\n',\n",
       "    '    if not os.path.exists(pdf_dir):\\n',\n",
       "    '        print(f\"Advertencia: No se encontró el directorio para {pdf_name}\")\\n',\n",
       "    '        continue\\n',\n",
       "    '        \\n',\n",
       "    \"    total_pages = info['total_pages']\\n\",\n",
       "    \"    target_pages = info['target_pages']\\n\",\n",
       "    '    \\n',\n",
       "    '    for page in range(total_pages):\\n',\n",
       "    \"        img_path = os.path.join(pdf_dir, f'page_{page}.png')\\n\",\n",
       "    '        if not os.path.exists(img_path):\\n',\n",
       "    '            print(f\"Advertencia: No se encontró la página {page} de {pdf_name}\")\\n',\n",
       "    '            continue\\n',\n",
       "    '            \\n',\n",
       "    '        # Cargar y preprocesar imagen\\n',\n",
       "    '        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\\n',\n",
       "    '        img = cv2.resize(img, (224, 224))\\n',\n",
       "    '        img = img / 255.0\\n',\n",
       "    '        X.append(img[..., np.newaxis])\\n',\n",
       "    '        y.append(1 if page in target_pages else 0)\\n',\n",
       "    '\\n',\n",
       "    'X = np.array(X)\\n',\n",
       "    'y = np.array(y)\\n',\n",
       "    '\\n',\n",
       "    'print(f\"✓ Datos preparados:\")\\n',\n",
       "    'print(f\"  - Total de imágenes: {len(X)}\")\\n',\n",
       "    'print(f\"  - Primeras páginas: {sum(y)}\")\\n',\n",
       "    'print(f\"  - Otras páginas: {len(y) - sum(y)}\")']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['# Dividir datos en entrenamiento y validación\\n',\n",
       "    'print(\"Dividiendo datos en conjuntos de entrenamiento y validación...\")\\n',\n",
       "    'X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\\n',\n",
       "    'print(f\"✓ Conjunto de entrenamiento: {len(X_train)} imágenes\")\\n',\n",
       "    'print(f\"✓ Conjunto de validación: {len(X_val)} imágenes\")']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['# Definir el modelo\\n',\n",
       "    'print(\"Construyendo modelo...\")\\n',\n",
       "    'model = Sequential([\\n',\n",
       "    \"    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)),\\n\",\n",
       "    '    MaxPooling2D((2, 2)),\\n',\n",
       "    \"    Conv2D(64, (3, 3), activation='relu'),\\n\",\n",
       "    '    MaxPooling2D((2, 2)),\\n',\n",
       "    \"    Conv2D(64, (3, 3), activation='relu'),\\n\",\n",
       "    '    Flatten(),\\n',\n",
       "    \"    Dense(64, activation='relu'),\\n\",\n",
       "    '    Dropout(0.5),\\n',\n",
       "    \"    Dense(1, activation='sigmoid')\\n\",\n",
       "    '])\\n',\n",
       "    '\\n',\n",
       "    'model.compile(\\n',\n",
       "    \"    optimizer='adam',\\n\",\n",
       "    \"    loss='binary_crossentropy',\\n\",\n",
       "    \"    metrics=['accuracy']\\n\",\n",
       "    ')\\n',\n",
       "    '\\n',\n",
       "    'model.summary()']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['# Entrenar modelo\\n',\n",
       "    'print(\"Iniciando entrenamiento...\")\\n',\n",
       "    'history = model.fit(\\n',\n",
       "    '    X_train, y_train,\\n',\n",
       "    '    epochs=20,\\n',\n",
       "    '    batch_size=32,\\n',\n",
       "    '    validation_data=(X_val, y_val),\\n',\n",
       "    '    callbacks=[\\n',\n",
       "    '        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\\n',\n",
       "    '        tf.keras.callbacks.ModelCheckpoint(\\n',\n",
       "    \"            os.path.join(MODEL_DIR, 'best_model.h5'),\\n\",\n",
       "    '            save_best_only=True\\n',\n",
       "    '        )\\n',\n",
       "    '    ]\\n',\n",
       "    ')']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['# Visualizar resultados\\n',\n",
       "    'plt.figure(figsize=(12, 4))\\n',\n",
       "    '\\n',\n",
       "    '# Gráfico de pérdida\\n',\n",
       "    'plt.subplot(1, 2, 1)\\n',\n",
       "    \"plt.plot(history.history['loss'], label='Training Loss')\\n\",\n",
       "    \"plt.plot(history.history['val_loss'], label='Validation Loss')\\n\",\n",
       "    \"plt.title('Model Loss')\\n\",\n",
       "    \"plt.xlabel('Epoch')\\n\",\n",
       "    \"plt.ylabel('Loss')\\n\",\n",
       "    'plt.legend()\\n',\n",
       "    '\\n',\n",
       "    '# Gráfico de precisión\\n',\n",
       "    'plt.subplot(1, 2, 2)\\n',\n",
       "    \"plt.plot(history.history['accuracy'], label='Training Accuracy')\\n\",\n",
       "    \"plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\\n\",\n",
       "    \"plt.title('Model Accuracy')\\n\",\n",
       "    \"plt.xlabel('Epoch')\\n\",\n",
       "    \"plt.ylabel('Accuracy')\\n\",\n",
       "    'plt.legend()\\n',\n",
       "    '\\n',\n",
       "    'plt.tight_layout()\\n',\n",
       "    'plt.show()\\n',\n",
       "    '\\n',\n",
       "    '# Guardar gráficos\\n',\n",
       "    \"plt.savefig(os.path.join(MODEL_DIR, 'training_history.png'))\\n\",\n",
       "    'print(\"✓ Gráficos guardados en\", os.path.join(MODEL_DIR, \\'training_history.png\\'))']}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "   'file_extension': '.py',\n",
       "   'mimetype': 'text/x-python',\n",
       "   'name': 'python',\n",
       "   'nbconvert_exporter': 'python',\n",
       "   'pygments_lexer': 'ipython3',\n",
       "   'version': '3.8.0'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Entrenamiento del Modelo de Clasificación de Páginas de PDF\\n\",\n",
    "    \"\\n\",\n",
    "    \"Este notebook entrena un modelo de CNN para identificar las primeras páginas en documentos PDF.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Importar librerías necesarias\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import cv2\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"from tensorflow.keras.models import Sequential\\n\",\n",
    "    \"from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Configurar rutas\\n\",\n",
    "    \"PROCESSED_DIR = '../data/processed/2-TITULOS-15-DE-NOVIEMBRE-2024-1-30'\\n\",\n",
    "    \"LABELS_FILE = '../data/labels.json'\\n\",\n",
    "    \"MODEL_DIR = '../data/models'\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Verificar existencia de archivos y directorios necesarios\\n\",\n",
    "    \"print(\\\"Verificando archivos y directorios...\\\")\\n\",\n",
    "    \"if not os.path.exists(LABELS_FILE):\\n\",\n",
    "    \"    raise FileNotFoundError(f\\\"No se encontró el archivo de etiquetas: {LABELS_FILE}\\\")\\n\",\n",
    "    \"if not os.path.exists(PROCESSED_DIR):\\n\",\n",
    "    \"    raise FileNotFoundError(f\\\"No se encontró el directorio de imágenes procesadas: {PROCESSED_DIR}\\\")\\n\",\n",
    "    \"os.makedirs(MODEL_DIR, exist_ok=True)\\n\",\n",
    "    \"print(\\\"✓ Verificación completada\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Cargar etiquetas\\n\",\n",
    "    \"print(\\\"Cargando etiquetas...\\\")\\n\",\n",
    "    \"with open(LABELS_FILE, 'r') as f:\\n\",\n",
    "    \"    labels = json.load(f)\\n\",\n",
    "    \"print(f\\\"✓ Se cargaron etiquetas para {len(labels)} PDFs\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Preparar datos para entrenamiento\\n\",\n",
    "    \"print(\\\"Preparando datos para entrenamiento...\\\")\\n\",\n",
    "    \"X = []\\n\",\n",
    "    \"y = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"for pdf_name, info in labels.items():\\n\",\n",
    "    \"    pdf_dir = os.path.join(PROCESSED_DIR, pdf_name)\\n\",\n",
    "    \"    if not os.path.exists(pdf_dir):\\n\",\n",
    "    \"        print(f\\\"Advertencia: No se encontró el directorio para {pdf_name}\\\")\\n\",\n",
    "    \"        continue\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    total_pages = info['total_pages']\\n\",\n",
    "    \"    target_pages = info['target_pages']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for page in range(total_pages):\\n\",\n",
    "    \"        img_path = os.path.join(pdf_dir, f'page_{page}.png')\\n\",\n",
    "    \"        if not os.path.exists(img_path):\\n\",\n",
    "    \"            print(f\\\"Advertencia: No se encontró la página {page} de {pdf_name}\\\")\\n\",\n",
    "    \"            continue\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        # Cargar y preprocesar imagen\\n\",\n",
    "    \"        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\\n\",\n",
    "    \"        img = cv2.resize(img, (224, 224))\\n\",\n",
    "    \"        img = img / 255.0\\n\",\n",
    "    \"        X.append(img[..., np.newaxis])\\n\",\n",
    "    \"        y.append(1 if page in target_pages else 0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"X = np.array(X)\\n\",\n",
    "    \"y = np.array(y)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"✓ Datos preparados:\\\")\\n\",\n",
    "    \"print(f\\\"  - Total de imágenes: {len(X)}\\\")\\n\",\n",
    "    \"print(f\\\"  - Primeras páginas: {sum(y)}\\\")\\n\",\n",
    "    \"print(f\\\"  - Otras páginas: {len(y) - sum(y)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Dividir datos en entrenamiento y validación\\n\",\n",
    "    \"print(\\\"Dividiendo datos en conjuntos de entrenamiento y validación...\\\")\\n\",\n",
    "    \"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\\n\",\n",
    "    \"print(f\\\"✓ Conjunto de entrenamiento: {len(X_train)} imágenes\\\")\\n\",\n",
    "    \"print(f\\\"✓ Conjunto de validación: {len(X_val)} imágenes\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Definir el modelo\\n\",\n",
    "    \"print(\\\"Construyendo modelo...\\\")\\n\",\n",
    "    \"model = Sequential([\\n\",\n",
    "    \"    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)),\\n\",\n",
    "    \"    MaxPooling2D((2, 2)),\\n\",\n",
    "    \"    Conv2D(64, (3, 3), activation='relu'),\\n\",\n",
    "    \"    MaxPooling2D((2, 2)),\\n\",\n",
    "    \"    Conv2D(64, (3, 3), activation='relu'),\\n\",\n",
    "    \"    Flatten(),\\n\",\n",
    "    \"    Dense(64, activation='relu'),\\n\",\n",
    "    \"    Dropout(0.5),\\n\",\n",
    "    \"    Dense(1, activation='sigmoid')\\n\",\n",
    "    \"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"model.compile(\\n\",\n",
    "    \"    optimizer='adam',\\n\",\n",
    "    \"    loss='binary_crossentropy',\\n\",\n",
    "    \"    metrics=['accuracy']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"model.summary()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Entrenar modelo\\n\",\n",
    "    \"print(\\\"Iniciando entrenamiento...\\\")\\n\",\n",
    "    \"history = model.fit(\\n\",\n",
    "    \"    X_train, y_train,\\n\",\n",
    "    \"    epochs=20,\\n\",\n",
    "    \"    batch_size=32,\\n\",\n",
    "    \"    validation_data=(X_val, y_val),\\n\",\n",
    "    \"    callbacks=[\\n\",\n",
    "    \"        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\\n\",\n",
    "    \"        tf.keras.callbacks.ModelCheckpoint(\\n\",\n",
    "    \"            os.path.join(MODEL_DIR, 'best_model.h5'),\\n\",\n",
    "    \"            save_best_only=True\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"    ]\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Visualizar resultados\\n\",\n",
    "    \"plt.figure(figsize=(12, 4))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Gráfico de pérdida\\n\",\n",
    "    \"plt.subplot(1, 2, 1)\\n\",\n",
    "    \"plt.plot(history.history['loss'], label='Training Loss')\\n\",\n",
    "    \"plt.plot(history.history['val_loss'], label='Validation Loss')\\n\",\n",
    "    \"plt.title('Model Loss')\\n\",\n",
    "    \"plt.xlabel('Epoch')\\n\",\n",
    "    \"plt.ylabel('Loss')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Gráfico de precisión\\n\",\n",
    "    \"plt.subplot(1, 2, 2)\\n\",\n",
    "    \"plt.plot(history.history['accuracy'], label='Training Accuracy')\\n\",\n",
    "    \"plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\\n\",\n",
    "    \"plt.title('Model Accuracy')\\n\",\n",
    "    \"plt.xlabel('Epoch')\\n\",\n",
    "    \"plt.ylabel('Accuracy')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Guardar gráficos\\n\",\n",
    "    \"plt.savefig(os.path.join(MODEL_DIR, 'training_history.png'))\\n\",\n",
    "    \"print(\\\"✓ Gráficos guardados en\\\", os.path.join(MODEL_DIR, 'training_history.png'))\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
